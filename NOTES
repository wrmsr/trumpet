select * from pg_create_logical_replication_slot('trumpet', 'test_decoding');
select slot_name, plugin, slot_type, database, active, restart_lsn from pg_replication_slots;

select * from pg_logical_slot_get_changes('trumpet', null, null);

create table data(id serial primary key, data text);

select * from pg_logical_slot_get_changes('trumpet', null, null);
select * from pg_logical_slot_get_changes('trumpet', null, null);

begin;
insert into data(data) values('1');
insert into data(data) values('2');
commit;

select * from pg_logical_slot_get_changes('trumpet', null, null);

insert into data(data) values('3');

select * from pg_logical_slot_peek_changes('trumpet', null, null);
select * from pg_logical_slot_peek_changes('trumpet', null, null);
select * from pg_logical_slot_peek_changes('trumpet', null, null, 'include-timestamp', 'on');

select pg_drop_replication_slot('trumpet');





http://use-the-index-luke.com/blog/2014-01/unreasonable-defaults-primary-key-clustering-key
http://use-the-index-luke.com/sql/clustering/index-organized-clustered-index
http://use-the-index-luke.com/sql/clustering

https://www.postgresql.org/message-id/Pine.BSO.4.44.0206031939050.21627-100000@kitten.greentechnologist.org
http://dba.stackexchange.com/questions/65964/how-do-i-decompose-ctid-into-page-and-row-numbers

https://github.com/jbarham/gopgsqldriver
https://github.com/kardianos/govendor
https://github.com/Shopify/sarama
https://github.com/aws/aws-sdk-go
https://github.com/golang/go/issues/7408
https://github.com/go-gorp/gorp

https://github.com/Shopify/sarama

https://github.com/siddontang/go-mysql
-tags=embed github.com/tecbot/gorocksdb



govendor
mysql
postgres
swig

github.com/rlmcpherson/s3gof3r
github.com/aws/aws-sdk-go/service/s3
github.com/aws/aws-sdk-go/service/kinesis
github.com/jinzhu/gorm
github.com/jinzhu/gorm/dialects/mysql
github.com/jinzhu/gorm/dialects/postgres
github.com/jinzhu/gorm/dialects/sqlite3
github.com/Shopify/sarama




https://axialcorps.com/2014/06/24/named-locks-in-mysql-and-postgres/


s3/
 my_db/
  index/
   00001 (json)
  segments/
   00001 (json/gz)


segment:
 name
 created_date
 size_bytes
 num_rows
 min_sequence
 max_sequence

json schema

index file contains all information, rewritten in entirety every time
compaction done as in lucene
gc done by deleting all indices too old (with failsafe of at least one) then deleting any segment not referenced by any remaining index


could directly hive interop via create table / partition by segment / add partition
 select row_number() over (partition by id order by segment desc) rn, * from foo where rn = 1


new PUT only, r-a-w guaranteed
writing orchestrated by sql lock + generation info, reading can be done uncoordinated


tailer process
compaction/gc process
pg_xlog backup watchdog, kill pid and drop slot

schematizer? heartbeat daemon? failover?


https://github.com/2ndQuadrant/repmgr
https://wiki.postgresql.org/images/d/da/PGConfUS2016_Migrating_a_live_Postgres_database_into_RDS_with_no_downtime.pdf


INVARIANT:
 never receive more than one tuple per pk/sequence pair
